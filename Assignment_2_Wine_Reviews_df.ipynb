{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords\n",
    "from numpy.random import shuffle\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print \"Reading data...\"\n",
    "data_df = pd.read_json(\"winemag-data-130k-v2.json\",dtype={\n",
    "    'points': np.int32,\n",
    "    'price': np.float32,\n",
    "})\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data_df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of grape types used to make the wine: 707\n"
     ]
    }
   ],
   "source": [
    "variety_num = data_df['variety'].value_counts()\n",
    "print(\"The number of grape types used to make the wine: \" + str(len(variety_num)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinot Noir                  13272\n",
      "Chardonnay                  11753\n",
      "Cabernet Sauvignon           9472\n",
      "Red Blend                    8946\n",
      "Bordeaux-style Red Blend     6915\n",
      "Riesling                     5189\n",
      "Sauvignon Blanc              4967\n",
      "Syrah                        4142\n",
      "Rosé                         3564\n",
      "Merlot                       3102\n",
      "Name: variety, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print variety_num[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "variety_set = {u'Pinot Noir',u'Chardonnay',u'Cabernet Sauvignon',u'Red Blend',u'Bordeaux-style Red Blend',u'Riesling',u'Sauvignon Blanc',u'Syrah',u'Rosé',u'Merlot'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_new = []\n",
    "for d in data:\n",
    "    if d['variety'] in variety_set:\n",
    "        data_new.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71322"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_new\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "punctuation = set(string.punctuation)\n",
    "number = set(['0','1','2','3','4','5','6','7','8','9'])\n",
    "#stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#shuffle then split\n",
    "#train, valid, test: 1/3, 1/3, 1/3\n",
    "shuffle(data)\n",
    "train = data[:len(data)/3]\n",
    "valid = data[len(data)/3:2*len(data)/3]\n",
    "test  = data[2*len(data)/3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Description\n",
    "#1. Remove punctuation\n",
    "#2. Remove number\n",
    "#3. Stemming (NOT IN THIS CASE)\n",
    "#4. Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "wordCount = defaultdict(int)\n",
    "count = 0\n",
    "for d in train:\n",
    "    count += 1\n",
    "    r = ''.join([c for c in d['description'].lower() if not c in punctuation.union(number)])\n",
    "    for w in r.split():\n",
    "        #w = stemmer.stem(w) # with stemming\n",
    "        if w not in set(stopwords.words('english')):\n",
    "            wordCount[w] += 1\n",
    "    if count%10000==0:\n",
    "        print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "words = [x[1] for x in counts[0:4000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Description\n",
    "#1. Remove punctuation\n",
    "#2. Remove number\n",
    "#3. Stemming\n",
    "#4. Remove stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(x,y):\n",
    "    numerator = np.dot(x,y)\n",
    "    denominator = np.linalg.norm(x)*np.linalg.norm(y)\n",
    "    return round(numerator/float(denominator),3)\n",
    "\n",
    "def check_word(word):\n",
    "    feat = [0]*len(data)\n",
    "    for i in range(len(data)):\n",
    "        r = ''.join([c for c in data[i]['description'].lower() if not c in punctuation.union(number)])\n",
    "        if word in set(r.split()):\n",
    "            feat[i] = 1\n",
    "    return sum(feat)\n",
    "\n",
    "def idf(word):\n",
    "    return -math.log10(check_word(word)*1.0/len(data))\n",
    "\n",
    "def tf(word,datum):\n",
    "    r = ''.join([c for c in datum['description'].lower() if not c in punctuation])\n",
    "    return r.split().count(word)\n",
    "\n",
    "def tf_idf(word,datum):\n",
    "    return tf(word,datum)*idf(word)\n",
    "\n",
    "def performance(predictions, y):\n",
    "    correct = [(a==b) for (a,b) in zip(predictions,y)]\n",
    "    acc = sum(correct) * 1.0 / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18103810885841676"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if a comment includes words of the category name, then return that category.\n",
    "catDict = {\n",
    "    u'Pinot Noir': 0,\n",
    "    u'Chardonnay': 1,\n",
    "    u'Cabernet Sauvignon': 2,\n",
    "    u'Red Blend': 3,\n",
    "    u'Bordeaux-style Red Blend': 4,\n",
    "    u'Riesling': 5,\n",
    "    u'Sauvignon Blanc': 6,\n",
    "    u'Syrah': 7,\n",
    "    u'Rosé': 8,\n",
    "    u'Merlot': 9\n",
    "}\n",
    "baseline_predictions = []\n",
    "#baseline model:\n",
    "for d in test:\n",
    "    words = d[u'description'].lower()\n",
    "    cat = catDict[u'Pinot Noir']\n",
    "    if 'pinot' in words or 'noir' in words:\n",
    "        cat = catDict[u'Pinot Noir']\n",
    "    if 'chardonnay' in words:\n",
    "        cat = catDict[u'Chardonnay']\n",
    "    if 'cabernet' in words or 'sauvignon' in words:\n",
    "        cat = catDict[u'Cabernet Sauvignon']\n",
    "    if 'red' in words or 'blend':\n",
    "        cat = catDict[u'Red Blend']\n",
    "    if 'bordeaux' in words and ('red' in words or 'blend'): #special\n",
    "        cat = catDict[u'Bordeaux-style Red Blend']\n",
    "    if 'riesling' in words:\n",
    "        cat = catDict[u'Riesling']\n",
    "    if 'sauvignon' in words or 'blanc' in words:\n",
    "        cat = catDict[u'Sauvignon Blanc']\n",
    "    if 'syrah' in words:\n",
    "        cat = catDict[u'Syrah']\n",
    "    if 'ros' in words:\n",
    "        cat = catDict[u'Rosé']\n",
    "    if 'merlot' in words:\n",
    "        cat = catDict[u'Merlot']\n",
    "    baseline_predictions.append(cat)\n",
    "\n",
    "#evaluate baseline:\n",
    "corrects = []\n",
    "for d,p in zip(test,baseline_predictions):\n",
    "    cat = catDict[d[u'variety']]\n",
    "    corrects.append(cat==p)\n",
    "sum(corrects)*1.0/len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wordId = dict(zip(words, range(len(words))))\n",
    "wordSet = set(words)\n",
    "def feature(datum):\n",
    "    feat = [0]*len(words)\n",
    "    r = ''.join([c for c in datum['description'].lower() if not c in punctuation.union(number)])\n",
    "    for w in r.split():\n",
    "        if w in wordSet:\n",
    "            #feat[wordId[w]] += 1\n",
    "            feat[wordId[w]] = 1\n",
    "    feat.append(1) #offset\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = [feature(r) for r in train]\n",
    "X_valid = [feature(r) for r in valid]\n",
    "X_test = [feature(r) for r in test]\n",
    "\n",
    "y_train = [catDict[r['variety']] for r in train]\n",
    "y_valid = [catDict[r['variety']] for r in valid]\n",
    "y_test = [catDict[r['variety']] for r in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat = 0, C = 0.01: validation accuracy = 0.918692689493\n",
      "cat = 0, C = 0.1: validation accuracy = 0.921132329436\n",
      "cat = 0, C = 1: validation accuracy = 0.920585513586\n",
      "cat = 0, C = 10: validation accuracy = 0.918398250189\n",
      "cat = 0, C = 100: validation accuracy = 0.892445528729\n",
      "cat = 0, C = 3000: validation accuracy = 0.894001850761\n",
      "cat = 1, C = 0.01: validation accuracy = 0.94754774123\n",
      "cat = 1, C = 0.1: validation accuracy = 0.948220745352\n",
      "cat = 1, C = 1: validation accuracy = 0.945696979894\n",
      "cat = 1, C = 10: validation accuracy = 0.943131151678\n",
      "cat = 1, C = 100: validation accuracy = 0.925548918987\n",
      "cat = 1, C = 3000: validation accuracy = 0.921973584588\n",
      "cat = 2, C = 0.01: validation accuracy = 0.920543450829\n",
      "cat = 2, C = 0.1: validation accuracy = 0.91873475225\n",
      "cat = 2, C = 1: validation accuracy = 0.917430806764\n",
      "cat = 2, C = 10: validation accuracy = 0.915159417851\n",
      "cat = 2, C = 100: validation accuracy = 0.898334314798\n",
      "cat = 2, C = 3000: validation accuracy = 0.882981408261\n",
      "cat = 3, C = 0.01: validation accuracy = 0.937032051821\n",
      "cat = 3, C = 0.1: validation accuracy = 0.936190796669\n",
      "cat = 3, C = 1: validation accuracy = 0.934424160848\n",
      "cat = 3, C = 10: validation accuracy = 0.933456717422\n",
      "cat = 3, C = 100: validation accuracy = 0.922562463195\n",
      "cat = 3, C = 3000: validation accuracy = 0.906200050475\n",
      "cat = 4, C = 0.01: validation accuracy = 0.945654917136\n",
      "cat = 4, C = 0.1: validation accuracy = 0.948515184656\n",
      "cat = 4, C = 1: validation accuracy = 0.947295364684\n",
      "cat = 4, C = 10: validation accuracy = 0.945360477833\n",
      "cat = 4, C = 100: validation accuracy = 0.903381845714\n",
      "cat = 4, C = 3000: validation accuracy = 0.926263985867\n",
      "cat = 5, C = 0.01: validation accuracy = 0.976697232271\n",
      "cat = 5, C = 0.1: validation accuracy = 0.978421805334\n",
      "cat = 5, C = 1: validation accuracy = 0.974846470935\n",
      "cat = 5, C = 10: validation accuracy = 0.970598132414\n",
      "cat = 5, C = 100: validation accuracy = 0.967359300076\n",
      "cat = 5, C = 3000: validation accuracy = 0.967948178683\n",
      "cat = 6, C = 0.01: validation accuracy = 0.960797509885\n",
      "cat = 6, C = 0.1: validation accuracy = 0.963026836039\n",
      "cat = 6, C = 1: validation accuracy = 0.958862623034\n",
      "cat = 6, C = 10: validation accuracy = 0.954403970724\n",
      "cat = 6, C = 100: validation accuracy = 0.954193656936\n",
      "cat = 6, C = 3000: validation accuracy = 0.932236897451\n",
      "cat = 7, C = 0.01: validation accuracy = 0.961807016068\n",
      "cat = 7, C = 0.1: validation accuracy = 0.960965760915\n",
      "cat = 7, C = 1: validation accuracy = 0.958021367881\n",
      "cat = 7, C = 10: validation accuracy = 0.957642803062\n",
      "cat = 7, C = 100: validation accuracy = 0.926137797594\n",
      "cat = 7, C = 3000: validation accuracy = 0.923866408682\n",
      "cat = 8, C = 0.01: validation accuracy = 0.974972659208\n",
      "cat = 8, C = 0.1: validation accuracy = 0.97581391436\n",
      "cat = 8, C = 1: validation accuracy = 0.972280642719\n",
      "cat = 8, C = 10: validation accuracy = 0.967906115925\n",
      "cat = 8, C = 100: validation accuracy = 0.966770421469\n",
      "cat = 8, C = 3000: validation accuracy = 0.96727517456\n",
      "cat = 9, C = 0.01: validation accuracy = 0.969083873139\n",
      "cat = 9, C = 0.1: validation accuracy = 0.967401362833\n",
      "cat = 9, C = 1: validation accuracy = 0.965382350467\n",
      "cat = 9, C = 10: validation accuracy = 0.964414907041\n",
      "cat = 9, C = 100: validation accuracy = 0.930890889207\n",
      "cat = 9, C = 3000: validation accuracy = 0.960629258854\n"
     ]
    }
   ],
   "source": [
    "clfs = {}\n",
    "for cat in range(10):\n",
    "  y_trainC = [catDict[r['variety']] == cat for r in train]\n",
    "  y_validC = [catDict[r['variety']] == cat for r in valid]\n",
    "  bestAcc = 0\n",
    "  bestCLF = None\n",
    "  for c in 0.01, 0.1, 1, 10, 100, 3000:\n",
    "    clf = svm.LinearSVC(C = c)\n",
    "    clf.fit(X_train, y_trainC)\n",
    "    predictions = [x for x in clf.predict(X_valid)]\n",
    "    acc = [(x == y) for (x,y) in zip(predictions, y_validC)]\n",
    "    acc = sum(acc) * 1.0 / len(acc)\n",
    "    print(\"cat = \" + str(cat) + \", C = \" + str(c) + \": validation accuracy = \" + str(acc))\n",
    "    if acc > bestAcc:\n",
    "      bestAcc = acc\n",
    "      bestCLF = clf\n",
    "  clfs[cat] = bestCLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-SVM valid accuracy = 0.757970892572\n"
     ]
    }
   ],
   "source": [
    "confidences = {}\n",
    "for cat in range(10):\n",
    "    confidences[cat] = clfs[cat].decision_function(X_valid)\n",
    "\n",
    "predictions = []\n",
    "for i in range(len(confidences[0])):\n",
    "    cs = [(confidences[c][i],c) for c in range(10)]\n",
    "    cs.sort()\n",
    "    mostConfidentCategory = cs[-1][1]\n",
    "    predictions.append(mostConfidentCategory)\n",
    "\n",
    "validAcc = [(x == y) for (x,y) in zip(predictions, y_valid)]\n",
    "validAcc = sum(validAcc) * 1.0 / len(validAcc)\n",
    "\n",
    "print(\"Multi-SVM valid accuracy = \" + str(validAcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-SVM test accuracy = 0.750483721713\n"
     ]
    }
   ],
   "source": [
    "confidences = {}\n",
    "for cat in range(10):\n",
    "    confidences[cat] = clfs[cat].decision_function(X_test)\n",
    "\n",
    "predictions = []\n",
    "for i in range(len(confidences[0])):\n",
    "    cs = [(confidences[c][i],c) for c in range(10)]\n",
    "    cs.sort()\n",
    "    mostConfidentCategory = cs[-1][1]\n",
    "    predictions.append(mostConfidentCategory)\n",
    "\n",
    "testAcc = [(x == y) for (x,y) in zip(predictions, y_test)]\n",
    "testAcc = sum(testAcc) * 1.0 / len(testAcc)\n",
    "\n",
    "print(\"Multi-SVM test accuracy = \" + str(testAcc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf_idf feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCount2 = defaultdict(int)\n",
    "count2 = 0\n",
    "#stemmer = PorterStemmer()\n",
    "for d in train:\n",
    "    count2 += 1\n",
    "    r = ''.join([c for c in d['description'].lower() if not c in punctuation.union(number)])\n",
    "    for w in r.split():\n",
    "        #w = stemmer.stem(w) # with stemming\n",
    "        if w not in set(stopwords.words('english')):\n",
    "            wordCount2[w] += 1\n",
    "        #if count2%1000==0:\n",
    "            #print count2\n",
    "        \n",
    "counts2 = [(wordCount2[w], w) for w in wordCount2]\n",
    "counts2.sort()\n",
    "counts2.reverse()\n",
    "\n",
    "words2 = [x[1] for x in counts2[0:1000]]\n",
    "wordId2 = dict(zip(words2, range(len(words2))))\n",
    "wordSet2 = set(words2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_word(word):\n",
    "    feat = [0]*len(train)\n",
    "    for i in range(len(train)):\n",
    "        r = ''.join([c for c in train[i]['description'].lower() if not c in punctuation.union(number)])\n",
    "        if word in set(r.split()):\n",
    "            feat[i] = 1\n",
    "    return sum(feat)\n",
    "\n",
    "def idf(word):\n",
    "    return math.log10(len(train)*1.0/check_word(word))\n",
    "\n",
    "def tf(word,datum):\n",
    "    r = ''.join([c for c in datum['description'].lower() if not c in punctuation.union(number)])\n",
    "    return r.split().count(word)\n",
    "\n",
    "def tf_idf(word,datum):\n",
    "    return tf(word,datum)*idf(word)\n",
    "\n",
    "def getIDF(datum,word):\n",
    "    count = 0\n",
    "    for d in datum:\n",
    "        r = ''.join([c for c in d['description'].lower() if not c in punctuation])\n",
    "        rList = r.split()\n",
    "        if word in rList:\n",
    "            count += 1\n",
    "        #if count == 0:\n",
    "            #print word\n",
    "    return math.log(len(datum)/count*1.0,10)\n",
    "\n",
    "def getTF(data,word):\n",
    "    count = 0\n",
    "    r = ''.join([c for c in data['description'].lower() if not c in punctuation])\n",
    "    rList = r.split()\n",
    "    for l in rList:\n",
    "        if l == word:\n",
    "            count += 1\n",
    "    return count * 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_idf = [getIDF(train, w) for w in words2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_tf_idf(datum):\n",
    "    feat = [0]*len(words2)\n",
    "    for w in words2:\n",
    "        feat[wordId2[w]] = getTF(datum, w)*(word_idf[wordId2[w]])\n",
    "    feat.append(1) #offset\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish y train\n",
      "finish y valid\n",
      "finish y test\n",
      "finish x train\n",
      "finish x valid\n",
      "finish x test\n"
     ]
    }
   ],
   "source": [
    "y_train = [catDict[r['variety']] for r in train]\n",
    "print 'finish y train'\n",
    "y_valid = [catDict[r['variety']] for r in valid]\n",
    "print 'finish y valid'\n",
    "y_test = [catDict[r['variety']] for r in test]\n",
    "print 'finish y test'\n",
    "\n",
    "\n",
    "X_train = [feature_tf_idf(r) for r in train]\n",
    "print 'finish x train'\n",
    "X_valid = [feature_tf_idf(r) for r in valid]\n",
    "print 'finish x valid'\n",
    "X_test = [feature_tf_idf(r) for r in test]\n",
    "print 'finish x test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat = 0, C = 0.01: validation accuracy = 0.917304618491\n",
      "cat = 0, C = 0.1: validation accuracy = 0.916841928157\n",
      "cat = 0, C = 1: validation accuracy = 0.91642130058\n",
      "cat = 0, C = 10: validation accuracy = 0.912425338605\n",
      "cat = 0, C = 100: validation accuracy = 0.89438041558\n",
      "cat = 0, C = 3000: validation accuracy = 0.888407503996\n",
      "cat = 1, C = 0.01: validation accuracy = 0.946327921259\n",
      "cat = 1, C = 0.1: validation accuracy = 0.946496172289\n",
      "cat = 1, C = 1: validation accuracy = 0.943257339951\n",
      "cat = 1, C = 10: validation accuracy = 0.942331959283\n",
      "cat = 1, C = 100: validation accuracy = 0.928745688567\n",
      "cat = 1, C = 3000: validation accuracy = 0.929418692689\n",
      "cat = 2, C = 0.01: validation accuracy = 0.92016488601\n",
      "cat = 2, C = 0.1: validation accuracy = 0.918145873643\n",
      "cat = 2, C = 1: validation accuracy = 0.917683183309\n",
      "cat = 2, C = 10: validation accuracy = 0.914149911668\n",
      "cat = 2, C = 100: validation accuracy = 0.867165811391\n",
      "cat = 2, C = 3000: validation accuracy = 0.856397745436\n",
      "cat = 3, C = 0.01: validation accuracy = 0.934802725667\n",
      "cat = 3, C = 0.1: validation accuracy = 0.934171784302\n",
      "cat = 3, C = 1: validation accuracy = 0.933414654665\n",
      "cat = 3, C = 10: validation accuracy = 0.927525868596\n",
      "cat = 3, C = 100: validation accuracy = 0.915033229579\n",
      "cat = 3, C = 3000: validation accuracy = 0.909354757298\n",
      "cat = 4, C = 0.01: validation accuracy = 0.947421552957\n",
      "cat = 4, C = 0.1: validation accuracy = 0.946369984016\n",
      "cat = 4, C = 1: validation accuracy = 0.945444603348\n",
      "cat = 4, C = 10: validation accuracy = 0.943551779255\n",
      "cat = 4, C = 100: validation accuracy = 0.913603095819\n",
      "cat = 4, C = 3000: validation accuracy = 0.935433667031\n",
      "cat = 5, C = 0.01: validation accuracy = 0.978547993606\n",
      "cat = 5, C = 0.1: validation accuracy = 0.97493059645\n",
      "cat = 5, C = 1: validation accuracy = 0.969504500715\n",
      "cat = 5, C = 10: validation accuracy = 0.966518044923\n",
      "cat = 5, C = 100: validation accuracy = 0.960040380247\n",
      "cat = 5, C = 3000: validation accuracy = 0.962606208463\n",
      "cat = 6, C = 0.01: validation accuracy = 0.963026836039\n",
      "cat = 6, C = 0.1: validation accuracy = 0.961218137461\n",
      "cat = 6, C = 1: validation accuracy = 0.958484058215\n",
      "cat = 6, C = 10: validation accuracy = 0.956170606545\n",
      "cat = 6, C = 100: validation accuracy = 0.944014469589\n",
      "cat = 6, C = 3000: validation accuracy = 0.944855724741\n",
      "cat = 7, C = 0.01: validation accuracy = 0.961428451249\n",
      "cat = 7, C = 0.1: validation accuracy = 0.958820560276\n",
      "cat = 7, C = 1: validation accuracy = 0.957516614789\n",
      "cat = 7, C = 10: validation accuracy = 0.953520652814\n",
      "cat = 7, C = 100: validation accuracy = 0.945276352318\n",
      "cat = 7, C = 3000: validation accuracy = 0.932110709178\n",
      "cat = 8, C = 0.01: validation accuracy = 0.974089341297\n",
      "cat = 8, C = 0.1: validation accuracy = 0.973879027509\n",
      "cat = 8, C = 1: validation accuracy = 0.968999747623\n",
      "cat = 8, C = 10: validation accuracy = 0.96639185665\n",
      "cat = 8, C = 100: validation accuracy = 0.964709346345\n",
      "cat = 8, C = 3000: validation accuracy = 0.955076974846\n",
      "cat = 9, C = 0.01: validation accuracy = 0.965760915286\n",
      "cat = 9, C = 0.1: validation accuracy = 0.963573651889\n",
      "cat = 9, C = 1: validation accuracy = 0.962269706402\n",
      "cat = 9, C = 10: validation accuracy = 0.958862623034\n",
      "cat = 9, C = 100: validation accuracy = 0.950408008749\n",
      "cat = 9, C = 3000: validation accuracy = 0.942962900648\n"
     ]
    }
   ],
   "source": [
    "clfs = {}\n",
    "for cat in range(10):\n",
    "  y_trainC = [catDict[r['variety']] == cat for r in train]\n",
    "  y_validC = [catDict[r['variety']] == cat for r in valid]\n",
    "  bestAcc = 0\n",
    "  bestCLF = None\n",
    "  for c in 0.01, 0.1, 1, 10, 100, 3000:\n",
    "    clf = svm.LinearSVC(C = c)\n",
    "    clf.fit(X_train, y_trainC)\n",
    "    predictions = [x for x in clf.predict(X_valid)]\n",
    "    acc = [(x == y) for (x,y) in zip(predictions, y_validC)]\n",
    "    acc = sum(acc) * 1.0 / len(acc)\n",
    "    print(\"cat = \" + str(cat) + \", C = \" + str(c) + \": validation accuracy = \" + str(acc))\n",
    "    if acc > bestAcc:\n",
    "      bestAcc = acc\n",
    "      bestCLF = clf\n",
    "  clfs[cat] = bestCLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-SVM valid accuracy = 0.753932867839\n"
     ]
    }
   ],
   "source": [
    "confidences = {}\n",
    "for cat in range(10):\n",
    "    confidences[cat] = clfs[cat].decision_function(X_valid)\n",
    "\n",
    "predictions = []\n",
    "for i in range(len(confidences[0])):\n",
    "    cs = [(confidences[c][i],c) for c in range(10)]\n",
    "    cs.sort()\n",
    "    mostConfidentCategory = cs[-1][1]\n",
    "    predictions.append(mostConfidentCategory)\n",
    "\n",
    "validAcc = [(x == y) for (x,y) in zip(predictions, y_valid)]\n",
    "validAcc = sum(validAcc) * 1.0 / len(validAcc)\n",
    "\n",
    "print(\"Multi-SVM valid accuracy = \" + str(validAcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-SVM test accuracy = 0.759022461513\n"
     ]
    }
   ],
   "source": [
    "confidences = {}\n",
    "for cat in range(10):\n",
    "    confidences[cat] = clfs[cat].decision_function(X_test)\n",
    "\n",
    "predictions = []\n",
    "for i in range(len(confidences[0])):\n",
    "    cs = [(confidences[c][i],c) for c in range(10)]\n",
    "    cs.sort()\n",
    "    mostConfidentCategory = cs[-1][1]\n",
    "    predictions.append(mostConfidentCategory)\n",
    "\n",
    "testAcc = [(x == y) for (x,y) in zip(predictions, y_test)]\n",
    "testAcc = sum(testAcc) * 1.0 / len(testAcc)\n",
    "\n",
    "print(\"Multi-SVM test accuracy = \" + str(testAcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
